# CSV-Crunch

A tiny, fast C++23 commandâ€‘line tool for streaming CSV inspection. Start simple (row counting and header handling), then grow into filtering, statistics, histograms, and groupâ€‘byâ€”step by step.

> This repository is intentionally incremental. Each mission adds a focused capability with clean commits and docs so you can follow the learning path.

---

## Features (current)

* âš™ï¸ **Streaming I/O**: reads CSV lineâ€‘byâ€‘line (no fullâ€‘file loads).
* ðŸ§­ **Header detection**: first line is treated as a header.
* ðŸªŸ **CRLF tolerance**: trims trailing `\r` for Windows CSV files.
* ðŸ“¤ **Clear diagnostics & exit codes**.

Planned next features (see Roadmap):

* CSV parsing (no quotes â†’ full RFC4180-ish quotes/escapes)
* Online statistics (Welford mean/variance, online median)
* ASCII histograms
* Row filtering with a tiny expression language
* Groupâ€‘by aggregations

---

## Quickstart

### Build with CMake (recommended)

```bash
cmake -S . -B build -DCMAKE_BUILD_TYPE=Release
cmake --build build -j
./build/csvsum data/sample.csv fare
```

> **Requires**: a C++23 compiler (GCC â‰¥ 13, Clang â‰¥ 16, or MSVC 19.36+), CMake â‰¥ 3.20.

### CLion

1. Put your CSVs in `data/` (or anywhere you like).
2. **Run â†’ Edit Configurationsâ€¦**

   * **Program arguments:** `data/sample.csv fare`
   * **Working directory:** `$ProjectFileDir$`
3. Run the target `csvsum`.

### Windows notes

* **MSVC (Visual Studio 2022 Build Tools):**

  * Use *Developer PowerShell* / *x64 Native Tools Prompt*.
  * Build: `cl /std:c++23 /O2 /W4 /EHsc main.cpp /Fe:csvsum.exe`
* **MSYS2 (g++):**

  * Install UCRT64 toolchain: `pacman -S --needed mingw-w64-ucrt-x86_64-toolchain`
  * Build: `g++ -std=c++23 -O2 -Wall -Wextra -pedantic main.cpp -o csvsum.exe`
* **WSL (Ubuntu):**

  * `sudo apt install g++` then `g++ -std=c++23 -O2 -Wall -Wextra -pedantic main.cpp -o csvsum`

---

## Usage

```
csvsum <file.csv> <column-name>
```

### Examples

```bash
# Count data rows (ignores empty lines)
./csvsum data/sample.csv fare
rows: 3
```

> The `column-name` is accepted early for future features (summary, hist, filter) and validates CLI shape. In current stage it is not used beyond the interface.

---

## Exit codes

* `0` â€” success
* `1` â€” usage error (not enough arguments)
* `2` â€” cannot open input file
* `3` â€” empty file (no header line)

Clear, scriptâ€‘friendly semantics make it easy to integrate in pipelines.

---

## Development

### Code style

* C++23, warnings cranked up (`-Wall -Wextra -pedantic`).
* Trim Windows `\r` on input lines to avoid invisible tail characters.
* Prefer streaming and singleâ€‘pass algorithms for large files.

### Recommended directory layout (as the project grows)

```
.
â”œâ”€â”€ app/              # CLI entrypoints (later)
â”œâ”€â”€ include/          # public headers
â”œâ”€â”€ src/              # implementations
â”œâ”€â”€ tests/            # unit tests
â”œâ”€â”€ data/             # sample CSVs
â”œâ”€â”€ CMakeLists.txt
â””â”€â”€ README.md
```

---

## Roadmap (incremental missions)

1. **Parser (no quotes)** â€” split on commas, preserve empty fields. â€” âœ…
2. Quoted fields (embedded commas) â€” âœ…
3. **Header lookup** â€” resolve column index by name.
4. **Online stats** â€” Welford mean/variance; online median (two heaps).
5. **ASCII histograms** â€” `hist <file> --col X --bins N`.
6. **Quoted CSV** â€” RFC4180-ish quotes and `""` escapes.
7. **Row filtering** â€” tiny expression language: `fare>50 && name=='Alice'`.
8. **Groupâ€‘by** â€” `--by <column>` with online aggregations per group.
9. **Parallel pipeline** â€” chunked reading + worker threads.

Each step will come with tests, docs, and a focused commit.

---

## Contributing

* Keep PRs small and focused.
* Add tests for every new feature or bugfix.
* Use conventional commit messages, e.g.:

  * `feat(parser): split by comma without quotes`
  * `fix(cli): print usage to stderr`
  * `test(stats): add welford edge cases`

---

## License

MIT Â© 2025
